{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40987,
     "status": "ok",
     "timestamp": 1683822777678,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "j4oF6LoiN_3T",
    "outputId": "19a18f41-77bc-4a28-ba6a-bb99dec067d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.29.0-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting language_tool_python\n",
      "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (4.65.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.4)\n",
      "Installing collected packages: language_tool_python\n",
      "Successfully installed language_tool_python-2.7.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=75b23347b48be09b0c83c680d2f66a7538e08dd46b114b6e2458eeb2c4184747\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting emoji (from stanza)\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.22.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.27.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.0+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.65.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234911 sha256=9c8fbdb35b0a3977f4576af77b92e723976805a4f8ef2a48911d3a2dd7542b64\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.2.0 stanza-1.5.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting natasha\n",
      "  Downloading natasha-1.5.0-py3-none-any.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.9.1)\n",
      "Collecting razdel>=0.5.0 (from natasha)\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Collecting navec>=0.9.0 (from natasha)\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Collecting slovnet>=0.6.0 (from natasha)\n",
      "  Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yargy>=0.14.0 (from natasha)\n",
      "  Downloading yargy-0.15.1-py3-none-any.whl (33 kB)\n",
      "Collecting ipymarkup>=0.8.0 (from natasha)\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from navec>=0.9.0->natasha) (1.22.4)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26099 sha256=8344be9cdb02a7d0b22b2bf66842a32c4374e120f012f7d36d98fb4f1f309255\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: razdel, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.5.0 navec-0.10.0 razdel-0.5.0 slovnet-0.6.0 yargy-0.15.1\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!pip install --upgrade transformers\n",
    "!pip install language_tool_python\n",
    "!pip install pymorphy2\n",
    "!pip install stanza\n",
    "!pip install spacy\n",
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1683822789493,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "2ww9huEwO4ng"
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import itertools\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1683822790652,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "2-InmVieO4k-"
   },
   "outputs": [],
   "source": [
    "cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']\n",
    "numbers = ['sing', 'plur']\n",
    "genders = ['masc', 'femn', 'neut']\n",
    "tenses = ['past', 'pres', 'futr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1683822792244,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "Ukqqy5gHO4iM"
   },
   "outputs": [],
   "source": [
    "def get_word(p, param):\n",
    "  if len(param) == 3:\n",
    "    word = p.inflect({param[0], param[1], param[2]})\n",
    "  else:\n",
    "    word = p.inflect({param[0], param[1]})\n",
    "  if word is not None:\n",
    "    return word.word\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "def get_inflected_words(keyword):\n",
    "  p = morph.parse(keyword)[0]\n",
    "  inflected_words = []\n",
    "  if 'VERB' in p.tag or 'INFN' in p.tag:\n",
    "    for param in itertools.product(numbers, tenses, genders):\n",
    "      word = get_word(p, param)\n",
    "      if word is not None:\n",
    "        inflected_words.append(word)\n",
    "    for param in itertools.product(numbers, tenses):\n",
    "      word = get_word(p, param)\n",
    "      if word is not None:\n",
    "        inflected_words.append(word)\n",
    "    for param in itertools.product(tenses, genders):\n",
    "      word = get_word(p, param)\n",
    "      if word is not None:\n",
    "        inflected_words.append(word)\n",
    "  else:\n",
    "    for param in itertools.product(numbers, cases, genders):\n",
    "      word = get_word(p, param)\n",
    "      if word is not None:\n",
    "        inflected_words.append(word)\n",
    "    for param in itertools.product(numbers, cases):\n",
    "      word = get_word(p, param)\n",
    "      if word is not None:\n",
    "        inflected_words.append(word)\n",
    "    for param in itertools.product(cases, genders):\n",
    "      word = get_word(p, param)\n",
    "      if word is not None:\n",
    "        inflected_words.append(word)\n",
    "  return list(set(inflected_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 17548,
     "status": "ok",
     "timestamp": 1683822812874,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "8WG10Ry9VycC"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from silero import silero_te\n",
    "import language_tool_python\n",
    "import pymorphy2\n",
    "import string\n",
    "import torch\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from text_analysis.segmentation import get_sentences\n",
    "from text_analysis.tokenization import get_tokens_natasha\n",
    "from text_analysis.morphology import get_morph_pymorphy\n",
    "import text_analysis\n",
    "\n",
    "# ---------------- SETTINGS SECTION ----------------\n",
    "\n",
    "# Number of attempts for correcting ending of the word\n",
    "attempts_change_ending = 5\n",
    "\n",
    "proba_gce_treshold = 0.01\n",
    "\n",
    "# list of languages to load\n",
    "languages = ['ru']  # ['ru', 'en', 'es', 'de', 'fr', 'ar', 'tr', 'uk']\n",
    "\n",
    "# --------------- LOAD MODELS ----------------\n",
    "\n",
    "ner_models = {}\n",
    "\n",
    "porter_stem = None\n",
    "silero_model = None\n",
    "\n",
    "def init():\n",
    "    global languages, porter_stem, silero_model, tokenizer_bert, model_bert,\\\n",
    "        PRE_TRAINED_MODEL_NAME_BERT\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if 'ru' in languages:\n",
    "        PRE_TRAINED_MODEL_NAME_BERT = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "        tokenizer_bert = GPT2Tokenizer.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
    "        model_bert = GPT2LMHeadModel.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
    "        model_bert.eval()\n",
    "        model_bert.to(device)\n",
    "        porter_stem = SnowballStemmer(\"russian\")\n",
    "        silero_model, example_texts, languages, punct, apply_te = silero_te()\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ------------- WORD ENDING CORRECTION -------------\n",
    "\n",
    "def correct_stem(stem, tokenizer_bert):\n",
    "    bert_predicted_index = tokenizer_bert.encode(stem)[1:-1]\n",
    "    roberta_tokens = []\n",
    "    for index in bert_predicted_index:\n",
    "        roberta_tokens.append(tokenizer_bert.decode([index]))\n",
    "    if len(roberta_tokens[-1]) == 1:\n",
    "        stem = tokenizer_bert.decode(bert_predicted_index[:-1])\n",
    "    return stem\n",
    "\n",
    "\n",
    "def check_match_lemmas(keyword_parsed, predicted_keyword_parsed):\n",
    "    if predicted_keyword_parsed['lemma'] == keyword_parsed['lemma'] \\\n",
    "            and (('sing' in predicted_keyword_parsed['feats'] and 'sing' in keyword_parsed['feats'])\n",
    "                 or ('plur' in predicted_keyword_parsed['feats'] and 'plur' in keyword_parsed['feats'])):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_corrected_keyword(keyword, keyword_stem, predicted_token, lang):\n",
    "    punct = string.punctuation + '...'\n",
    "    if predicted_token not in punct:\n",
    "        grammar = get_tokens_natasha(keyword)\n",
    "        grammar = get_morph_pymorphy(grammar, '', True)\n",
    "        keyword_parsed = {'lemma': grammar[0][0], 'feats': grammar[0][3]}\n",
    "\n",
    "        predicted_keyword = keyword_stem + predicted_token\n",
    "        grammar = get_tokens_natasha(predicted_keyword)\n",
    "        grammar = get_morph_pymorphy(grammar, '', True)\n",
    "        predicted_keyword_parsed = {'lemma': grammar[0][0], 'feats': grammar[0][3]}\n",
    "\n",
    "        if check_match_lemmas(keyword_parsed, predicted_keyword_parsed):\n",
    "            return predicted_keyword\n",
    "\n",
    "        predicted_keyword = keyword_stem[:-1] + predicted_token\n",
    "        grammar = get_tokens_natasha(predicted_keyword)\n",
    "        grammar = get_morph_pymorphy(grammar, '', True)\n",
    "        predicted_keyword_parsed = {'lemma': grammar[0][0], 'feats': grammar[0][3]}\n",
    "        if check_match_lemmas(keyword_parsed, predicted_keyword_parsed):\n",
    "            return predicted_keyword\n",
    "\n",
    "        predicted_keyword = porter_stem.stem(keyword) + predicted_token\n",
    "        grammar = get_tokens_natasha(predicted_keyword)\n",
    "        grammar = get_morph_pymorphy(grammar, '', True)\n",
    "        predicted_keyword_parsed = {'lemma': grammar[0][0], 'feats': grammar[0][3]}\n",
    "        if check_match_lemmas(keyword_parsed, predicted_keyword_parsed):\n",
    "            return predicted_keyword\n",
    "\n",
    "    return ''\n",
    "\n",
    "\n",
    "def correct_keywords_col_bert(text, keywords_col, tokenizer_bert, model_bert, proba_gce_treshold, model_name, lang):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sentences = [sentence['text'] for sentence in get_sentences(text, lang, 0, 0)]\n",
    "    predicted_keywords = []\n",
    "    print('\\t\\tSentences:')\n",
    "    for sentence in sentences:\n",
    "        print('\\t\\t\\t' + sentence)\n",
    "    index_sentence = 0\n",
    "    index_keyword_col = 0\n",
    "    start_index_search_kw = 0\n",
    "    while index_sentence < len(sentences) and index_keyword_col < len(keywords_col):\n",
    "        keyword_col = keywords_col[index_keyword_col]\n",
    "        sentence = sentences[index_sentence]\n",
    "        if keyword_col in str(sentence[start_index_search_kw:]):\n",
    "            print('\\n\\t\\tSentence: ' + sentence)\n",
    "            start_index_keyword_col = sentence.index(keyword_col, start_index_search_kw)\n",
    "            prefix = sentence[:start_index_keyword_col].strip()\n",
    "            tail = sentence[start_index_keyword_col + len(keyword_col):]\n",
    "            start_index_search_kw += len(keyword_col)\n",
    "\n",
    "            grammar = get_tokens_natasha(keyword_col)\n",
    "            grammar = get_morph_pymorphy(grammar, '', False)\n",
    "            keyword_col_token_pos = [[item[0], item[2]] for item in grammar]\n",
    "\n",
    "            first_noun_index = 0\n",
    "            while first_noun_index < len(keyword_col_token_pos) - 1 and keyword_col_token_pos[first_noun_index][1] != 'NOUN':\n",
    "                first_noun_index += 1\n",
    "\n",
    "            for j in reversed(range(first_noun_index + 1, len(keyword_col_token_pos))):\n",
    "                tail = ' ' + keyword_col_token_pos[j][0] + tail\n",
    "            for i in reversed(range(first_noun_index + 1)):\n",
    "                keyword = keyword_col_token_pos[i][0]\n",
    "                keyword_stem_nltk = porter_stem.stem(keyword)\n",
    "                #keyword_stem = porter_stem.stem(keyword)\n",
    "                bert_predicted_indexes = tokenizer_bert.encode(keyword)\n",
    "                token_list = []\n",
    "                for index in bert_predicted_indexes:\n",
    "                  token_list.append(tokenizer_bert.decode(index))\n",
    "                if len(token_list) > 1:\n",
    "                  keyword_stem = ''.join(token_list[:-1])\n",
    "                elif len(token_list) == 1:\n",
    "                  keyword_stem = ''.join(token_list)\n",
    "                else:\n",
    "                  keyword_stem = None\n",
    "                print(f'Список токенов: {token_list}')\n",
    "                context = prefix + ''.join(\n",
    "                    [' ' + x[0] for x in keyword_col_token_pos[:i]]) + ' ' + keyword_stem\n",
    "                \n",
    "                context_w_o_stem = prefix + ''.join(\n",
    "                    [' ' + x[0] for x in keyword_col_token_pos[:i]]) + ' '\n",
    "                print('\\t\\tContext: ' + context)\n",
    "\n",
    "                num_return_sequences = 1000\n",
    "                input_tokens = tokenizer_bert.encode(context_w_o_stem, return_tensors=\"pt\").cuda()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model_bert.generate(input_tokens.cuda(), num_return_sequences= num_return_sequences,\n",
    "                                   max_length=10, \n",
    "                                   repetition_penalty=2.0,\n",
    "                                   do_sample=True,\n",
    "                                   top_k=50, top_p=0.95,\n",
    "                                   temperature=0.7)\n",
    "                '''\n",
    "                print('Варианты: ')\n",
    "                for i in range(num_return_sequences):\n",
    "                  print(tokenizer_bert.decode(outputs[i]))\n",
    "                '''\n",
    "              \n",
    "\n",
    "                print('\\t\\tKeyword stem: ' + keyword_stem)\n",
    "                k = 0\n",
    "                found = False\n",
    "                final_predicted_keyword = ''\n",
    "                inflected_words = get_inflected_words(keyword)\n",
    "                print(f'Похожие слова: {inflected_words}')\n",
    "                while k < num_return_sequences:\n",
    "                    generated_text = tokenizer_bert.decode(outputs[k])\n",
    "                    predicted_token = generated_text.replace(context_w_o_stem, '').split()[0]\n",
    "                    if predicted_token.startswith('##'):\n",
    "                        predicted_token = predicted_token.replace('##', '')\n",
    "                    else:\n",
    "                        if not 'roberta' in model_name.lower():\n",
    "                            predicted_token = ' ' + predicted_token\n",
    "                    punct = string.punctuation + '...'\n",
    "                    if keyword_stem == '':\n",
    "                      predicted_keyword = keyword_stem + predicted_token\n",
    "                    else:\n",
    "                      predicted_keyword = predicted_token\n",
    "                    predicted_keywords.append(predicted_keyword)\n",
    "                    print('\\t\\t\\t' + str(k + 1) + ' predicted token: ' + predicted_token)\n",
    "                    if len(predicted_keyword) > 0 and not found:\n",
    "                      if predicted_keyword in inflected_words or keyword_stem in predicted_keyword or keyword_stem_nltk in predicted_keyword:\n",
    "                        final_predicted_keyword = predicted_keyword\n",
    "                        found = True\n",
    "                        break\n",
    "                    k += 1\n",
    "                if not found and keyword not in tail:\n",
    "                    tail = ' ' + keyword + tail\n",
    "                elif found:\n",
    "                    tail = ' ' + final_predicted_keyword + tail\n",
    "\n",
    "            print('\\t\\tCorrected sentence: ' + prefix + tail)\n",
    "            sentences[index_sentence] = prefix + tail\n",
    "            sentences[index_sentence] = sentences[index_sentence].strip()\n",
    "            index_keyword_col += 1\n",
    "        else:\n",
    "            start_index_search_kw = 0\n",
    "            index_sentence += 1\n",
    "    return ' '.join(sentence for sentence in sentences), predicted_keywords, token_list\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "#исправление грамматических и орфографических ошибок с помощью LanguageTool (локально)\n",
    "def grammar_correction(text, lang, replaces_dict=None):\n",
    "    if replaces_dict != None:\n",
    "        replaces = [elem['new_string'] for elem in replaces_dict if elem['check']]\n",
    "        replaces_indexes = [[elem['result_start'], elem['result_start'] + len(elem['new_string']) -1] for elem in replaces_dict if elem['check']]\n",
    "    if not lang:\n",
    "        tool = language_tool_python.LanguageTool('auto')\n",
    "    else:\n",
    "        tool = language_tool_python.LanguageTool(lang)\n",
    "    if replaces_dict == None:\n",
    "        errors = tool.check(text)\n",
    "        matches = []\n",
    "        for error in errors:\n",
    "            if error.replacements is not None and error.offset is not None:\n",
    "                error_dict = {'error_word': text[error.offset:error.offset + error.errorLength],\n",
    "                            'start': error.offset, 'end': error.offset + error.errorLength - 1,\n",
    "                            'replacements': error.replacements}\n",
    "                matches.append(error_dict)\n",
    "        text_corrected = tool.correct(text)\n",
    "        grammar_dict = {'corrected_text': text_corrected, 'number_errors': len(errors)}\n",
    "        if len(errors) > 0:\n",
    "            grammar_dict['errors'] = matches\n",
    "    else:\n",
    "        number_errors = 0\n",
    "        text_corrected = text\n",
    "        matches = []\n",
    "        for i, word in enumerate(replaces):\n",
    "            if word == text[replaces_indexes[i][0]:replaces_indexes[i][1]]:\n",
    "                errors = tool.check(word)\n",
    "                number_errors += len(errors)\n",
    "                for error in errors:\n",
    "                    if error.replacements is not None and error.offset is not None:\n",
    "                        error_dict = {'error_word': text[error.offset:error.offset + error.errorLength],\n",
    "                                    'start': error.offset, 'end': error.offset + error.errorLength - 1,\n",
    "                                    'replacements': error.replacements}\n",
    "                        matches.append(error_dict)\n",
    "                word_corrected = tool.correct(word)\n",
    "                text_corrected[replaces_indexes[i][0]:replaces_indexes[i][1]] == word_corrected\n",
    "        text_corrected = correct_sentence(text_corrected)\n",
    "        grammar_dict = {'corrected_text': text_corrected, 'number_errors': number_errors}\n",
    "        if number_errors > 0:\n",
    "            grammar_dict['errors'] = matches\n",
    "    return grammar_dict\n",
    "\n",
    "\n",
    "#исправление пунктуционных ошибок в сегментированном тексте на предложения (предварительно очистив его от всех знаков пунктуации)\n",
    "def punctuation(text, lang, replaces_dict=None):\n",
    "    if replaces_dict != None:\n",
    "        replaces = [elem['new_string'] for elem in replaces_dict if elem['check']]\n",
    "        replaces_indexes = [[elem['result_start'], elem['result_start'] + len(elem['new_string']) -1] for elem in replaces_dict if elem['check']]\n",
    "    #функция, расставляющая знаки препинания с помощью моделей Silero (silero_te)\n",
    "    if replaces_dict == None:\n",
    "        sentences = get_sentences_without_punctuation(text, lang)\n",
    "        new_sentences = []\n",
    "        for sent in sentences:\n",
    "            sent = sent.lower()\n",
    "            output_text = silero_model.enhance_text(sent, lang)\n",
    "            new_sentences.append(output_text)\n",
    "        return ' '.join(new_sentences)\n",
    "    else:\n",
    "        output_text = text\n",
    "        for i, word in enumerate(replaces):\n",
    "            if word == text[replaces_indexes[i][0]:replaces_indexes[i][1]]:\n",
    "                output_word = silero_model.enhance_text(word, lang)\n",
    "                output_text[replaces_indexes[i][0]:replaces_indexes[i][1]] = output_word\n",
    "        return output_text\n",
    "   \n",
    "\n",
    "#удаление пробелов перед знаками препинания\n",
    "def correct_sentence(sentence):\n",
    "    for punct in string.punctuation:\n",
    "        if punct in sentence:\n",
    "            sentence = sentence.replace(' ' + punct, punct)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "#очистка предложений от пунктуации\n",
    "def get_sentences_without_punctuation(text, lang):\n",
    "    sentences = []\n",
    "    punct = string.punctuation\n",
    "    for sent in get_sentences(text, lang, min_sent_len=0, min_sent_words=0):\n",
    "        sentence = sent['text'].translate(str.maketrans('', '', punct))\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def agreement(text, keywords, lang):\n",
    "    corrected_sentence, predicted_keywords = correct_keywords_col_bert(text, keywords, tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang)\n",
    "    grammar_dict = {'corrected_text': corrected_sentence, 'replacements': predicted_keywords}\n",
    "    return grammar_dict\n",
    "\n",
    "\n",
    "def dep_word_agreement(original_text, changed_text, replaces, lang):\n",
    "    #токенизация исходного и конечного предложений\n",
    "    original_tokens = [item[0] for item in get_tokens_nltk(original_text, lang)]\n",
    "    changed_tokens = [item[0] for item in get_tokens_nltk(changed_text, lang)]\n",
    "    #получение списка изменённых слов в changed_text и их индексов\n",
    "    unique_changed_words = []\n",
    "    replaced_words = []\n",
    "    replaced_words_indexes = []\n",
    "    for elem in replaces:\n",
    "        if elem['check']:\n",
    "            replaced_words.append(elem['new_string'])\n",
    "            replaced_words_indexes.append([elem['result_start'], elem['result_start'] + len(elem['new_string']) - 1])\n",
    "    changed_words_indexes = []\n",
    "    for i in range(len(changed_tokens)):\n",
    "        for j in range(len(replaced_words)):\n",
    "            if changed_tokens[i] == replaced_words[j] and changed_tokens[i] == changed_text[replaced_words_indexes[j][0]: replaced_words_indexes[j][1] + 1]:\n",
    "                unique_changed_words.append(changed_tokens[i])\n",
    "                changed_words_indexes.append(i)\n",
    "    #получение grammar на основе токенов исходного предложения для использования внешней функции без изменений\n",
    "    original_tokens_grammar = [[token, '', '', '', '', ''] for token in original_tokens]\n",
    "    changed_tokens_grammar = [[token, '', '', '', '', ''] for token in changed_tokens]\n",
    "    #добавление в grammar значений параметров word_id и head_id из внешней функции синтаксического анализа\n",
    "    original_syntax = get_syntax_stanza([original_tokens_grammar], lang)\n",
    "    changed_syntax = get_syntax_stanza([changed_tokens_grammar], lang)\n",
    "    #получение списка head_ids (списка индексов связанных слов)\n",
    "    head_ids = [item[5] for item in changed_tokens_grammar]\n",
    "    #получение списка связанных слов и списка их индексов в changed_text\n",
    "    linked_words_list = []\n",
    "    linked_words_indexes = []\n",
    "    for index in changed_words_indexes:\n",
    "        linked_words = []\n",
    "        for i in range(len(head_ids)):\n",
    "            if index + 1 in head_ids:\n",
    "                if index + 1 == head_ids[i]:\n",
    "                    linked_words.append(changed_tokens[i])\n",
    "                    linked_words_indexes.append(i)\n",
    "        linked_words_list.append(linked_words)\n",
    "    #реализация морфологии для слов из unique_changed_words и связанных слов из linked_words\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    morph_unique_list = []\n",
    "    morph_linked_list = []\n",
    "    for word in unique_changed_words:\n",
    "        morph_unique_list.append(morph.parse(word)[0])\n",
    "    for i in range(len(linked_words_list)):\n",
    "        changed_words_list = []\n",
    "        for elem in linked_words_list[i]:\n",
    "            changed_words_list.append(morph.parse(elem)[0])\n",
    "        morph_linked_list.append(changed_words_list)\n",
    "    #получение списка морфологических признаков для слов из unique_changed_words\n",
    "    morph_tags = [item.tag for item in morph_unique_list]\n",
    "    #получение списка связанных слов с перенесёнными морфологическими признаками относительно признаков слов из unique_changed_words\n",
    "    inflected_words_list = []\n",
    "    for i, tag in enumerate(morph_tags):\n",
    "        inflected_words = []\n",
    "        for elem in morph_linked_list[i]:\n",
    "            if 'VERB' in tag or 'GRND' in tag:\n",
    "                inflected_words.append(elem.inflect({tag.number, tag.gender}).word)\n",
    "            elif 'ADJF' in tag or 'ADJS' in tag or 'PRTF' in tag or 'PRTS' in tag:\n",
    "                inflected_words.append(elem.inflect({tag.number, tag.gender, tag.case}).word)\n",
    "        inflected_words_list.append(inflected_words)\n",
    "    #замена форм связанных слов в конечном предложении\n",
    "    for elem in inflected_words_list:\n",
    "        if len(elem) > 0:\n",
    "            linked_word_index = 0\n",
    "            for i in range(len(changed_tokens)):\n",
    "                if i in linked_words_indexes:\n",
    "                    changed_tokens[i] = elem[linked_word_index]\n",
    "                    linked_word_index += 1\n",
    "    #возврат правильного предложения\n",
    "    grammar_dict = {'corrected_text': correct_sentence(' '.join(changed_tokens))}\n",
    "    return grammar_dict\n",
    "\n",
    "# Parameter method can take one of the values \"spelling\", \"punctuation\", \"grammar\"\n",
    "def error_correction(messages, methods=[\"spelling\", 'punctuation', 'grammar']):\n",
    "    messages_new = copy.deepcopy(messages)\n",
    "    for message in messages_new:\n",
    "        text = message['text']\n",
    "        replaces = None\n",
    "        if 'replaces' in message.keys():\n",
    "            replaces = message[\"replaces\"]\n",
    "        lang = None\n",
    "        if 'lang' in message:\n",
    "            lang = message['lang']\n",
    "        grammar_dict = {}\n",
    "        for method in methods:\n",
    "            if method == 'spelling':\n",
    "                if replaces == None:\n",
    "                    grammar_dict[method] = grammar_correction(text, lang)\n",
    "                else:\n",
    "                    grammar_dict[method] = grammar_correction(message['result_text'], lang, replaces)\n",
    "            elif method == 'punctuation':\n",
    "                if lang is not None:\n",
    "                    if replaces == None:\n",
    "                        grammar_dict[method] = {'corrected_text': punctuation(text, lang)}\n",
    "                    else:\n",
    "                        grammar_dict[method] = {'corrected_text': punctuation(message['result_text'], lang, replaces)}\n",
    "                else:\n",
    "                    grammar_dict[method] = {'corrected_text': text}\n",
    "            elif method == 'grammar':\n",
    "                if 'replaced_words' in message:\n",
    "                    grammar_dict[method] = agreement(text, message['replaced_words'], lang)\n",
    "                if 'result_text' in message:\n",
    "                    grammar_dict[method] = dep_word_agreement(text, message['result_text'], replaces, lang)\n",
    "        if len(grammar_dict) > 0:\n",
    "            message['error_correction'] = grammar_dict\n",
    "    return messages_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1683822815625,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "F0dDn2B8QNBh",
    "outputId": "e87d5a99-6d07-49fa-cd0a-e73240ae041e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "8580e7f0f04b405e97f36b3480443cc0",
      "ca3e30d1daa349bba2ad9b4b0351e53b",
      "53b1349a4fb24fe4a6435c07ebe90999",
      "e22b9f0a665740579009b2593b1dbb3e",
      "90dc24b74bb540e988b19972f13f49bb",
      "ed449ef6bc8f45149d74b2cd2f530b22",
      "b327a53aa73a4665b8da3658e8d894f4",
      "e0944970655f4c90a76e39620b3ab386",
      "fe5fde3a4e66414d846723f87497aa62",
      "cb269958e8bf4cfe83b58b252faf83b7",
      "67af8e974ca94888a3090e0ddc83f677",
      "ad9158bf2fb646008af4912e30a3690e",
      "da11079ff3724c3b9764f801b29d78e9",
      "205e55ef30dc4c0ca3fee6cd361b13f4",
      "4b6e98de6af84781aa41afc60a84af84",
      "40f3f653f81c4d9f96ec541fab12085f",
      "5a57d269824944159361e707ce8ca2ef",
      "080867ff6a804bf9a7fdfbdd092a6415",
      "9c99b533e545459eb648e769835f2cfa",
      "5863ff15bb3e4be490916a299b4671b5",
      "5cfc03e6f94e4982b70fc2e0cb81c051",
      "770efc9cd1c04d0499ca443975f0780a"
     ]
    },
    "executionInfo": {
     "elapsed": 8808,
     "status": "ok",
     "timestamp": 1683822826103,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "SMQvMzi0RgqP",
    "outputId": "aa4cc552-7b93-4b7c-df1b-9ae70750abec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8580e7f0f04b405e97f36b3480443cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9158bf2fb646008af4912e30a3690e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.5.0/models/tokenize/gsd.pt:   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Loading these models for language: ru (Russian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "=======================\n",
      "\n",
      "INFO:stanza:Using device: cuda\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import text_analysis\n",
    "text_analysis.morphology.init()\n",
    "text_analysis.segmentation.init()\n",
    "text_analysis.tokenization.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1683822911803,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "sXyYqbIUzpVZ"
   },
   "outputs": [],
   "source": [
    "examples = {\n",
    "    'AGR_CASE': ['Город Каталония - после Ис Гр Войны - был таким грустном местом где ничего не хватало и опасно было ходить из за нужды в ремонте, но люди не были добиты а наоборот, они были полными надеждой.',\n",
    "                 'Анархизм - политическая система, которая предполагает отсутствие государства и наличия стихийной народной власти.'],\n",
    "    'AGR_NUM': ['Главное различия в том, что здесь я работаю в благотворительном обществе, а в Америке я больше всего работала в бизнесе или в университете.', \n",
    "                'Догма - это основные положение истины, неизменную любых обстоятельствах.'],\n",
    "    'AGR_PERS': ['На премьеру фильма пришли не много людей.', \n",
    "                 'Другие факторы приводя к потере языка, такие как война, стихийные бедствия, голод, болезнь и тому подобные, которые часто вызывают гибель целых общин, и, конечно, мы не можем предвидеть и предотвратить их.'],\n",
    "    'BREV': ['Например: современный культурный человек должен владеть каким-либо иностранным языком, быть способным работать с компьютером, в то время как в 19 веке культурный человек должен был умело владеть шпагой, или работать на земле, то есть культура всегда исторична и социальная.',\n",
    "             'Торговля услугами и товарами примерно одинаковая в развитых странах и развивающихся странах.'],\n",
    "    'GENDER': ['Почему Сталин одобрял монументальную архитектуру?&gt;. Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображала рост и поднятие страны ее развитие).',\n",
    "               'Translate the questions and answer them&gt;. Что было самый главной проблемой Петра Первого, когда он принимал престол?'],\n",
    "    'NUM': ['Напишите черновик краткой аннотации к своей курсовой работе.&gt;. В работе рассматривается разные виды компьютерных игр и их влияние на образование детей.', \n",
    "            'bibliography&gt;. В статье автор анализирует отношение между языком и мышлением'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "executionInfo": {
     "elapsed": 6778,
     "status": "error",
     "timestamp": 1683822920409,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "2Q2QupgxzpPq",
    "outputId": "2644b17d-1c2b-454b-9d13-06dca032fcd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 13, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tГород Каталония - после Ис Гр Войны - был таким грустном местом где ничего не хватало и опасно было ходить из за нужды в ремонте, но люди не были добиты а наоборот, они были полными надеждой.\n",
      "\n",
      "\t\tSentence: Город Каталония - после Ис Гр Войны - был таким грустном местом где ничего не хватало и опасно было ходить из за нужды в ремонте, но люди не были добиты а наоборот, они были полными надеждой.\n",
      "Список токенов: ['гру', 'стном']\n",
      "\t\tContext: Город Каталония - после Ис Гр Войны - был таким гру\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cad770e09a3c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AGR_CASE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                                         proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n\u001b[1;32m      6\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-570eab36dded>\u001b[0m in \u001b[0;36mcorrect_keywords_col_bert\u001b[0;34m(text, keywords_col, tokenizer_bert, model_bert, proba_gce_treshold, model_name, lang)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     outputs = model_bert.generate(input_tokens.cuda(), num_return_sequences= num_return_sequences,\n\u001b[0m\u001b[1;32m    161\u001b[0m                                    \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                                    \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1566\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2624\u001b[0m             \u001b[0;31m# pre-process distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_warper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0;31m# Store scores, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0msorted_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0mcumulative_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 14.75 GiB total capacity; 11.50 GiB already allocated; 342.81 MiB free; 13.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "keywords = [['грустном'], ['наличия']]\n",
    "i = 0\n",
    "for elem in examples['AGR_CASE']:\n",
    "      corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34642,
     "status": "ok",
     "timestamp": 1683822261079,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "6qN4ze1WzpJj",
    "outputId": "0696ac81-60c2-45a0-872e-8a422515c2c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tГлавное различия в том, что здесь я работаю в благотворительном обществе, а в Америке я больше всего работала в бизнесе или в университете.\n",
      "\n",
      "\t\tSentence: Главное различия в том, что здесь я работаю в благотворительном обществе, а в Америке я больше всего работала в бизнесе или в университете.\n",
      "Список токенов: ['раз', 'ли', 'чия']\n",
      "\t\tContext: Главное разли\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: разли\n",
      "Похожие слова: ['различиями', 'различиям', 'различий', 'различиях', 'различии', 'различия', 'различию', 'различием', 'различие']\n",
      "\t\t\t1 predicted token: Главное???\n",
      "\t\t\t2 predicted token: _неприятно.<s>\n",
      "\t\t\t3 predicted token: -\n",
      "\t\t\t4 predicted token: —\n",
      "\t\t\t5 predicted token: –\n",
      "\t\t\t6 predicted token: простить.<s>\n",
      "\t\t\t7 predicted token: потреблять\n",
      "\t\t\t8 predicted token: _непреодолимо.<s>\n",
      "\t\t\t9 predicted token: —\n",
      "\t\t\t10 predicted token: это,\n",
      "\t\t\t11 predicted token: Главное??\n",
      "\t\t\t12 predicted token: _то,\n",
      "\t\t\t13 predicted token: -\n",
      "\t\t\t14 predicted token: для\n",
      "\t\t\t15 predicted token: _для\n",
      "\t\t\t16 predicted token: _то,\n",
      "\t\t\t17 predicted token: _в\n",
      "\t\t\t18 predicted token: сделать\n",
      "\t\t\t19 predicted token: _это\n",
      "\t\t\t20 predicted token: ь,\n",
      "\t\t\t21 predicted token: это\n",
      "\t\t\t22 predicted token: это\n",
      "\t\t\t23 predicted token: истинного\n",
      "\t\t\t24 predicted token: —\n",
      "\t\t\t25 predicted token: бы\n",
      "\t\t\t26 predicted token: необходимо\n",
      "\t\t\t27 predicted token: того,\n",
      "\t\t\t28 predicted token: _это\n",
      "\t\t\t29 predicted token: –\n",
      "\t\t\t30 predicted token: ))))<s>\n",
      "\t\t\t31 predicted token: не\n",
      "\t\t\t32 predicted token: это\n",
      "\t\t\t33 predicted token: –\n",
      "\t\t\t34 predicted token: _заставить\n",
      "\t\t\t35 predicted token: сделать\n",
      "\t\t\t36 predicted token: что\n",
      "\t\t\t37 predicted token: древнерусского\n",
      "\t\t\t38 predicted token: ыше-е!!!\n",
      "\t\t\t39 predicted token: —\n",
      "\t\t\t40 predicted token: Главное???\n",
      "\t\t\t41 predicted token: ыо,\n",
      "\t\t\t42 predicted token: -\n",
      "\t\t\t43 predicted token: ___\n",
      "\t\t\t44 predicted token: такое,\n",
      "\t\t\t45 predicted token: же,\n",
      "\t\t\t46 predicted token: Главное???\n",
      "\t\t\t47 predicted token: Главное???\n",
      "\t\t\t48 predicted token: Главное???\n",
      "\t\t\t49 predicted token: ===\n",
      "\t\t\t50 predicted token: –\n",
      "\t\t\t51 predicted token: Главное?!\n",
      "\t\t\t52 predicted token: свидание.\n",
      "\t\t\t53 predicted token: того,\n",
      "\t\t\t54 predicted token: что\n",
      "\t\t\t55 predicted token: _ничего\n",
      "\t\t\t56 predicted token: то,\n",
      "\t\t\t57 predicted token: ьы\n",
      "\t\t\t58 predicted token: _что?\n",
      "\t\t\t59 predicted token: это\n",
      "\t\t\t60 predicted token: Главное?..\n",
      "\t\t\t61 predicted token: Главное???\n",
      "\t\t\t62 predicted token: несколько\n",
      "\t\t\t63 predicted token: попытки\n",
      "\t\t\t64 predicted token: быть\n",
      "\t\t\t65 predicted token: это\n",
      "\t\t\t66 predicted token: _\n",
      "\t\t\t67 predicted token: Главное??\n",
      "\t\t\t68 predicted token: это\n",
      "\t\t\t69 predicted token: Главное???\n",
      "\t\t\t70 predicted token: же,\n",
      "\t\t\t71 predicted token: _всегда\n",
      "\t\t\t72 predicted token: это\n",
      "\t\t\t73 predicted token: Главное!!<s>\n",
      "\t\t\t74 predicted token: всякое\n",
      "\t\t\t75 predicted token: Главное???\n",
      "\t\t\t76 predicted token: -\n",
      "\t\t\t77 predicted token: —\n",
      "\t\t\t78 predicted token: Главное???\n",
      "\t\t\t79 predicted token: Главное??\n",
      "\t\t\t80 predicted token: _это\n",
      "\t\t\t81 predicted token: ))))<s>\n",
      "\t\t\t82 predicted token: —\n",
      "\t\t\t83 predicted token: это\n",
      "\t\t\t84 predicted token: взаимодействие\n",
      "\t\t\t85 predicted token: _несколько\n",
      "\t\t\t86 predicted token: выбирай.\n",
      "\t\t\t87 predicted token: ыо?\n",
      "\t\t\t88 predicted token: –\n",
      "\t\t\t89 predicted token: —\n",
      "\t\t\t90 predicted token: это\n",
      "\t\t\t91 predicted token: Главное??\n",
      "\t\t\t92 predicted token: истинно\n",
      "\t\t\t93 predicted token: обнаруживать\n",
      "\t\t\t94 predicted token: всеми\n",
      "\t\t\t95 predicted token: —\n",
      "\t\t\t96 predicted token: _это\n",
      "\t\t\t97 predicted token: —\n",
      "\t\t\t98 predicted token: Главное???\n",
      "\t\t\t99 predicted token: _постоянно\n",
      "\t\t\t100 predicted token: счастья,\n",
      "\t\tCorrected sentence: Главное различия в том, что здесь я работаю в благотворительном обществе, а в Америке я больше всего работала в бизнесе или в университете.\n",
      "\t\tSentences:\n",
      "\t\t\tДогма - это основные положение истины, неизменную любых обстоятельствах.\n",
      "\n",
      "\t\tSentence: Догма - это основные положение истины, неизменную любых обстоятельствах.\n",
      "Список токенов: ['основ', 'ные']\n",
      "\t\tContext: Догма - это основ\n",
      "\t\tKeyword stem: основ\n",
      "Похожие слова: ['основную', 'основной', 'основном', 'основных', 'основная', 'основными', 'основным', 'основного', 'основному', 'основные', 'основное']\n",
      "\t\t\t1 predicted token: судьба,\n",
      "\t\t\t2 predicted token: Догма\n",
      "\t\t\t3 predicted token: \"Истина,\n",
      "\t\t\t4 predicted token: неизбежность.\n",
      "\t\t\t5 predicted token: свобода\n",
      "\t\t\t6 predicted token: Собрание\n",
      "\t\t\t7 predicted token: Устав,\n",
      "\t\t\t8 predicted token: Догма\n",
      "\t\t\t9 predicted token: \"доказательство\".<s>\n",
      "\t\t\t10 predicted token: священный\n",
      "\t\t\t11 predicted token: неотъемлемая\n",
      "\t\t\t12 predicted token: внутренний,\n",
      "\t\t\t13 predicted token: учебное\n",
      "\t\t\t14 predicted token: Закон,\n",
      "\t\t\t15 predicted token: Православие,\n",
      "\t\t\t16 predicted token: порядок\n",
      "\t\t\t17 predicted token: неприкосновенность,\n",
      "\t\tCorrected sentence: Догма - это неприкосновенность, положение истины, неизменную любых обстоятельствах.\n"
     ]
    }
   ],
   "source": [
    "keywords = [['различия'], ['основные']]\n",
    "i = 0\n",
    "for elem in examples['AGR_NUM']:\n",
    "      corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29837,
     "status": "ok",
     "timestamp": 1683822315637,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "FyAkOKLTzpFJ",
    "outputId": "9fb99394-a4c3-45da-fa30-ea520c6485e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tНа премьеру фильма пришли не много людей.\n",
      "\n",
      "\t\tSentence: На премьеру фильма пришли не много людей.\n",
      "Список токенов: ['при', 'шли']\n",
      "\t\tContext: На премьеру фильма при\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: при\n",
      "Похожие слова: ['прислала', 'прислал', 'пришлём', 'пришлю', 'прислало', 'прислали']\n",
      "\t\t\t1 predicted token: Дам\n",
      "\t\t\t2 predicted token: \"Свой\n",
      "\t\t\t3 predicted token: \"Призрак\n",
      "\t\t\t4 predicted token: \"Брат\n",
      "\t\t\t5 predicted token: \"Ночь\n",
      "\t\t\t6 predicted token: «Дорога»\n",
      "\t\t\t7 predicted token: \"Сны\n",
      "\t\t\t8 predicted token: `Откуда\n",
      "\t\t\t9 predicted token: «Небеса\n",
      "\t\t\t10 predicted token: \"Легенда\n",
      "\t\t\t11 predicted token: \"Четыре\n",
      "\t\t\t12 predicted token: \"Стиляги-2\".\n",
      "\t\t\t13 predicted token: Олег\n",
      "\t\t\t14 predicted token: \"Классный\n",
      "\t\t\t15 predicted token: \"Кролик\n",
      "\t\t\t16 predicted token: \"Не\n",
      "\t\t\t17 predicted token: `Пятьдесят\n",
      "\t\t\t18 predicted token: \"Невский\n",
      "\t\t\t19 predicted token: \"Анатомия\n",
      "\t\t\t20 predicted token: \"Матильда\".\n",
      "\t\t\t21 predicted token: «Планета\n",
      "\t\t\t22 predicted token: \"Пираты\n",
      "\t\t\t23 predicted token: `Пятница-13'\"\n",
      "\t\t\t24 predicted token: \"Холодное\n",
      "\t\t\t25 predicted token: `Побег'\"\n",
      "\t\t\t26 predicted token: \"Любовь\n",
      "\t\t\t27 predicted token: «В\n",
      "\t\t\t28 predicted token: \"Сорок\n",
      "\t\t\t29 predicted token: \"Духless\n",
      "\t\t\t30 predicted token: В\n",
      "\t\t\t31 predicted token: Оригинал\n",
      "\t\t\t32 predicted token: \"Грань\n",
      "\t\t\t33 predicted token: \"Дневник\n",
      "\t\t\t34 predicted token: «Остров»\n",
      "\t\t\t35 predicted token: \"Побег\n",
      "\t\t\t36 predicted token: `Полет\n",
      "\t\t\t37 predicted token: Олег\n",
      "\t\t\t38 predicted token: \"Салемские\n",
      "\t\t\t39 predicted token: \"Точка\n",
      "\t\t\t40 predicted token: в\n",
      "\t\t\t41 predicted token: http://www.kinopoiskusstvo-roditelskoe/filmslotyi_avtomatikov<s>\n",
      "\t\t\t42 predicted token: «Академия\n",
      "\t\t\t43 predicted token: \"Не\n",
      "\t\t\t44 predicted token: Вадим\n",
      "\t\t\t45 predicted token: `Сын\n",
      "\t\t\t46 predicted token: `Уловка-22'\n",
      "\t\t\t47 predicted token: ы\n",
      "\t\t\t48 predicted token: `Призрак\n",
      "\t\t\t49 predicted token: \"Сумерки.\n",
      "\t\t\t50 predicted token: Кинотеатр\n",
      "\t\t\t51 predicted token: Кинематографисты\n",
      "\t\t\t52 predicted token: \"Пассажир,\n",
      "\t\t\t53 predicted token: `Брат-2:\n",
      "\t\t\t54 predicted token: «Кококо»\n",
      "\t\t\t55 predicted token: \"Дорога\n",
      "\t\t\t56 predicted token: вчерашний\n",
      "\t\t\t57 predicted token: «Любовь\n",
      "\t\t\t58 predicted token: `'Великий\n",
      "\t\t\t59 predicted token: \"Четвертая\n",
      "\t\t\t60 predicted token: \"Праздник,\n",
      "\t\t\t61 predicted token: в\n",
      "\t\t\t62 predicted token: \"Тонкая\n",
      "\t\t\t63 predicted token: \"Враг\n",
      "\t\t\t64 predicted token: \"Горец\",\n",
      "\t\t\t65 predicted token: «Нелюбовь»\n",
      "\t\t\t66 predicted token: Кинофестиваль\n",
      "\t\t\t67 predicted token: \"Голодные\n",
      "\t\t\t68 predicted token: «Пролетая\n",
      "\t\t\t69 predicted token: Кристина\n",
      "\t\t\t70 predicted token: \"Легенда\n",
      "\t\t\t71 predicted token: \"Бойцовский\n",
      "\t\t\t72 predicted token: \"Кот\n",
      "\t\t\t73 predicted token: \"Культурная\n",
      "\t\t\t74 predicted token: В\n",
      "\t\t\t75 predicted token: `Гадкий\n",
      "\t\t\t76 predicted token: \"Навсегда\".<s>:))\n",
      "\t\t\t77 predicted token: \"Исход:\n",
      "\t\t\t78 predicted token: Вера\n",
      "\t\t\t79 predicted token: `Сумерки.\n",
      "\t\t\t80 predicted token: \"Груз\n",
      "\t\t\t81 predicted token: «Супермальчик»\n",
      "\t\t\t82 predicted token: «Нерожденный»\n",
      "\t\t\t83 predicted token: Я,\n",
      "\t\t\t84 predicted token: \"Берегись\n",
      "\t\t\t85 predicted token: \"Призрак\n",
      "\t\t\t86 predicted token: \"В\n",
      "\t\t\t87 predicted token: \"Дух\n",
      "\t\t\t88 predicted token: напрямик,\n",
      "\t\t\t89 predicted token: \"Оставайся\n",
      "\t\t\t90 predicted token: \"Брат-2.\n",
      "\t\t\t91 predicted token: \"Дух\n",
      "\t\t\t92 predicted token: ыз\n",
      "\t\t\t93 predicted token: \"Побег\n",
      "\t\t\t94 predicted token: в\n",
      "\t\t\t95 predicted token: \"Пятница,\n",
      "\t\t\t96 predicted token: В.Бушин,\n",
      "\t\t\t97 predicted token: \"Собачья\n",
      "\t\t\t98 predicted token: Билли\n",
      "\t\t\t99 predicted token: в\n",
      "\t\t\t100 predicted token: \"Неизвестный\n",
      "\t\tCorrected sentence: На премьеру фильма пришли не много людей.\n",
      "\t\tSentences:\n",
      "\t\t\tДругие факторы приводя к потере языка, такие как война, стихийные бедствия, голод, болезнь и тому подобные, которые часто вызывают гибель целых общин, и, конечно, мы не можем предвидеть и предотвратить их.\n",
      "\n",
      "\t\tSentence: Другие факторы приводя к потере языка, такие как война, стихийные бедствия, голод, болезнь и тому подобные, которые часто вызывают гибель целых общин, и, конечно, мы не можем предвидеть и предотвратить их.\n",
      "Список токенов: ['при', 'водя']\n",
      "\t\tContext: Другие факторы при\n",
      "\t\tKeyword stem: при\n",
      "Похожие слова: ['приводящую', 'приводящими', 'приводящим', 'приводящей', 'приводящих', 'приводящему', 'приводящее', 'приводящем', 'приводящего', 'приводящая', 'приводящие', 'приводящий']\n",
      "\t\t\t1 predicted token: —\n",
      "\t\t\t2 predicted token: Приведем\n",
      "\t\t\t3 predicted token: Сведения\n",
      "\t\t\t4 predicted token: Контроль\n",
      "\t\t\t5 predicted token: 1.\n",
      "\t\t\t6 predicted token: Повышенное\n",
      "\t\t\t7 predicted token: -\n",
      "\t\t\t8 predicted token: Соответственно,\n",
      "\t\t\t9 predicted token: У\n",
      "\t\t\t10 predicted token: Влияние\n",
      "\t\t\t11 predicted token: Число\n",
      "\t\t\t12 predicted token: Наиболее\n",
      "\t\t\t13 predicted token: 1.\n",
      "\t\t\t14 predicted token: В\n",
      "\t\t\t15 predicted token: Оказывается,\n",
      "\t\t\t16 predicted token: 1.\n",
      "\t\t\t17 predicted token: Вероятность\n",
      "\t\t\t18 predicted token: -\n",
      "\t\t\t19 predicted token: Сравнительный\n",
      "\t\t\t20 predicted token: Ученые\n",
      "\t\t\t21 predicted token: Существуют\n",
      "\t\t\t22 predicted token: В\n",
      "\t\t\t23 predicted token: По\n",
      "\t\t\t24 predicted token: По\n",
      "\t\t\t25 predicted token: 1.\n",
      "\t\t\t26 predicted token: Другое\n",
      "\t\t\t27 predicted token: влияют\n",
      "\t\t\t28 predicted token: Квартиры\n",
      "\t\t\t29 predicted token: Уровень\n",
      "\t\t\t30 predicted token: В\n",
      "\t\t\t31 predicted token: —\n",
      "\t\t\t32 predicted token: -\n",
      "\t\t\t33 predicted token: Влияние\n",
      "\t\t\t34 predicted token: -\n",
      "\t\t\t35 predicted token: —\n",
      "\t\t\t36 predicted token: Существует\n",
      "\t\t\t37 predicted token: -\n",
      "\t\t\t38 predicted token: Роль\n",
      "\t\t\t39 predicted token: -\n",
      "\t\t\t40 predicted token: 1.\n",
      "\t\t\t41 predicted token: Чистый\n",
      "\t\t\t42 predicted token: 1.\n",
      "\t\t\t43 predicted token: 1.\n",
      "\t\t\t44 predicted token: Вместе\n",
      "\t\t\t45 predicted token: В\n",
      "\t\t\t46 predicted token: Средняя\n",
      "\t\t\t47 predicted token: В\n",
      "\t\t\t48 predicted token: -\n",
      "\t\t\t49 predicted token: •\n",
      "\t\t\t50 predicted token: В\n",
      "\t\t\t51 predicted token: влияние\n",
      "\t\t\t52 predicted token: Ключевые\n",
      "\t\t\t53 predicted token: Развитие\n",
      "\t\t\t54 predicted token: Набор\n",
      "\t\t\t55 predicted token: Процент\n",
      "\t\t\t56 predicted token: •\n",
      "\t\t\t57 predicted token: 1.\n",
      "\t\t\t58 predicted token: В\n",
      "\t\t\t59 predicted token: Психологические\n",
      "\t\t\t60 predicted token: Наиболее\n",
      "\t\t\t61 predicted token: Существует\n",
      "\t\t\t62 predicted token: Наиболее\n",
      "\t\t\t63 predicted token: Существует\n",
      "\t\t\t64 predicted token: Питание.\n",
      "\t\t\t65 predicted token: Так\n",
      "\t\t\t66 predicted token: Как\n",
      "\t\t\t67 predicted token: Снижение\n",
      "\t\t\t68 predicted token: Вероятность\n",
      "\t\t\t69 predicted token: Существует\n",
      "\t\t\t70 predicted token: –\n",
      "\t\t\t71 predicted token: Количество\n",
      "\t\t\t72 predicted token: Пожалуй,\n",
      "\t\t\t73 predicted token: При\n",
      "\t\t\t74 predicted token: Повышенная\n",
      "\t\t\t75 predicted token: Количество\n",
      "\t\t\t76 predicted token: -\n",
      "\t\t\t77 predicted token: Наибольший\n",
      "\t\t\t78 predicted token: Влияние\n",
      "\t\t\t79 predicted token: Влияние\n",
      "\t\t\t80 predicted token: Уровень\n",
      "\t\t\t81 predicted token: Количество\n",
      "\t\t\t82 predicted token: Например,\n",
      "\t\tCorrected sentence: Другие факторы Например, к потере языка, такие как война, стихийные бедствия, голод, болезнь и тому подобные, которые часто вызывают гибель целых общин, и, конечно, мы не можем предвидеть и предотвратить их.\n"
     ]
    }
   ],
   "source": [
    "keywords = [['пришли'], ['приводя']]\n",
    "i = 0\n",
    "for elem in examples['AGR_PERS']:\n",
    "      corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1683122389060,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "1q3aeaVEzpAO",
    "outputId": "5ca6da31-061a-423d-9167-c8f2af6bfb2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 49, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tНапример: современный культурный человек должен владеть каким-либо иностранным языком, быть способным работать с компьютером, в то время как в 19 веке культурный человек должен был умело владеть шпагой, или работать на земле, то есть культура всегда исторична и социальная.\n",
      "\n",
      "\t\tSentence: Например: современный культурный человек должен владеть каким-либо иностранным языком, быть способным работать с компьютером, в то время как в 19 веке культурный человек должен был умело владеть шпагой, или работать на земле, то есть культура всегда исторична и социальная.\n",
      "Список токенов: ['социаль', 'ная']\n",
      "\t\tContext: Например: современный культурный человек должен владеть каким-либо иностранным языком, быть способным работать с компьютером, в то время как в 19 веке культурный человек должен был умело владеть шпагой, или работать на земле, то есть культура всегда исторична и социаль\n",
      "\t\tKeyword stem: социаль\n",
      "\t\t\t1 predicted token: социальна\n",
      "\t\tCorrected sentence: Например: современный культурный человек должен владеть каким-либо иностранным языком, быть способным работать с компьютером, в то время как в 19 веке культурный человек должен был умело владеть шпагой, или работать на земле, то есть культура всегда исторична и социальна.\n",
      "\t\tSentences:\n",
      "\t\t\tТорговля услугами и товарами примерно одинаковая в развитых странах и развивающихся странах.\n",
      "\n",
      "\t\tSentence: Торговля услугами и товарами примерно одинаковая в развитых странах и развивающихся странах.\n",
      "Список токенов: ['од', 'ина', 'ковая']\n",
      "\t\tContext: Торговля услугами и товарами примерно одина\n",
      "\t\tKeyword stem: одина\n",
      "\t\t\t1 predicted token: одинакова.\n",
      "\t\tCorrected sentence: Торговля услугами и товарами примерно одинакова. в развитых странах и развивающихся странах.\n"
     ]
    }
   ],
   "source": [
    "keywords = [['социальная'], ['одинаковая']]\n",
    "i = 0\n",
    "for elem in examples['BREV']:\n",
    "      corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1683122412022,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "ft0HpuZvzo8i",
    "outputId": "fa45979a-a290-4478-fb26-50606db36130"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tПочему Сталин одобрял монументальную архитектуру?&gt;.\n",
      "\t\t\tЯ думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображала рост и поднятие страны ее развитие).\n",
      "\n",
      "\t\tSentence: Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображала рост и поднятие страны ее развитие).\n",
      "Список токенов: ['от', 'ображ', 'ала']\n",
      "\t\tContext: Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображ\n",
      "\t\tKeyword stem: отображ\n",
      "\t\t\t1 predicted token: отображало\n",
      "\t\tCorrected sentence: Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображало рост и поднятие страны ее развитие).\n",
      "\t\tSentences:\n",
      "\t\t\tTranslate the questions and answer them&gt;.\n",
      "\t\t\tЧто было самый главной проблемой Петра Первого, когда он принимал престол?\n",
      "\n",
      "\t\tSentence: Что было самый главной проблемой Петра Первого, когда он принимал престол?\n",
      "Список токенов: ['сам', 'ый']\n",
      "\t\tContext: Что было сам\n",
      "\t\tKeyword stem: сам\n",
      "\t\t\t1 predicted token: сам\n",
      "\t\tCorrected sentence: Что было сам главной проблемой Петра Первого, когда он принимал престол?\n"
     ]
    }
   ],
   "source": [
    "keywords = [['отображала'], ['самый']]\n",
    "i = 0\n",
    "for elem in examples['GENDER']:\n",
    "      corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2002,
     "status": "ok",
     "timestamp": 1683122434725,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "u6K7ZFdJzowV",
    "outputId": "32aa1d14-4974-499a-9590-167edcff5ac6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tНапишите черновик краткой аннотации к своей курсовой работе.&gt;.\n",
      "\t\t\tВ работе рассматривается разные виды компьютерных игр и их влияние на образование детей.\n",
      "\n",
      "\t\tSentence: В работе рассматривается разные виды компьютерных игр и их влияние на образование детей.\n",
      "Список токенов: ['расс', 'матри', 'вается']\n",
      "\t\tContext: В работе рассматри\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: рассматри\n",
      "\t\t\t1 predicted token: рассматриваемого\n",
      "\t\tCorrected sentence: В работе рассматриваемого разные виды компьютерных игр и их влияние на образование детей.\n",
      "\t\tSentences:\n",
      "\t\t\tbibliography&gt;.\n",
      "\t\t\tВ статье автор анализирует отношение между языком и мышлением\n",
      "\n",
      "\t\tSentence: В статье автор анализирует отношение между языком и мышлением\n",
      "Список токенов: ['отно', 'шение']\n",
      "\t\tContext: В статье автор анализирует отно\n",
      "\t\tKeyword stem: отно\n",
      "\t\t\t1 predicted token: отношенческие\n",
      "\t\tCorrected sentence: В статье автор анализирует отношенческие между языком и мышлением\n"
     ]
    }
   ],
   "source": [
    "keywords = [['рассматривается'], ['отношение']]\n",
    "i = 0\n",
    "for elem in examples['NUM']:\n",
    "      corrected_sentence, predicted_keywords, token_list = correct_keywords_col_bert(elem, keywords[i], tokenizer_bert, model_bert,\n",
    "                                                                        proba_gce_treshold, PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NTvuKjrVE2f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def process_file(filenames):\n",
    "    files_encoding = 'UTF-8'\n",
    "    output_messages  = []\n",
    "    if not os.path.exists(filenames[1]):\n",
    "        with open(filenames[0], 'r', encoding=files_encoding) as f:\n",
    "            input_messages = pd.read_excel(filenames[0])\n",
    "        for i in range(len(input_messages)):\n",
    "          sentence, keywords = correct_keywords_col_bert(input_messages.loc[i, 'Prepared Sentence'], [input_messages.loc[i, 'Error']], tokenizer_bert, model_bert, proba_gce_treshold=0.01, model_name=PRE_TRAINED_MODEL_NAME_BERT, lang='ru')\n",
    "          output_messages.append({\n",
    "              'Original Sentence': input_messages.loc[i, 'Original Sentence'],\n",
    "              'Corrected Sentence': input_messages.loc[i,'Corrected Sentence'],\n",
    "              'Tag': input_messages.loc[i,'Tag'],\n",
    "              'Error': input_messages.loc[i,'Error'],\n",
    "              'Correction': input_messages.loc[i,'Correction'],\n",
    "              'Output Sentence': sentence,\n",
    "              'Output Keywords': keywords, \n",
    "          })\n",
    "        with open(filenames[1], 'w', encoding=files_encoding) as f:\n",
    "            writer = pd.ExcelWriter(filenames[1])\n",
    "            output_df = pd.DataFrame(output_messages)\n",
    "            output_df.to_excel(writer)\n",
    "            writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7036,
     "status": "ok",
     "timestamp": 1682169647127,
     "user": {
      "displayName": "Maitre Leone",
      "userId": "18380063945747377124"
     },
     "user_tz": -180
    },
    "id": "ngUE3cRZWl2c",
    "outputId": "c320578f-bc38-4202-fe40-a66731eabb8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSentences:\n",
      "\t\t\tТекст для Дни открытых дверей.\n",
      "\n",
      "\t\tSentence: Текст для Дни открытых дверей.\n",
      "\t\tContext: Текст для дни\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: дни\n",
      "\t\t\t1 predicted token: днища\n",
      "\t\tCorrected sentence: Текст для днища открытых дверей.\n",
      "\t\tSentences:\n",
      "\t\t\tКак вы понимаете, что такое идентичность?&gt;. чья-то идентичность это ответ на вопрос кто это такое?». такое идентичность формируется из всех разных вашей жизни, характера, идеологии, талантов и т.\n",
      "\n",
      "\t\tSentence: Как вы понимаете, что такое идентичность?&gt;. чья-то идентичность это ответ на вопрос кто это такое?». такое идентичность формируется из всех разных вашей жизни, характера, идеологии, талантов и т.\n",
      "\t\tContext: Как вы понимаете, что так\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: так\n",
      "\t\t\t1 predicted token: так\n",
      "\t\tCorrected sentence: Как вы понимаете, что так идентичность?&gt;. чья-то идентичность это ответ на вопрос кто это такое?». такое идентичность формируется из всех разных вашей жизни, характера, идеологии, талантов и т.\n",
      "\t\tSentences:\n",
      "\t\t\tМы знаем, что Земля вращается вокруг своей оси, то есть планет движется вокруг невидимой линии, которая идет через середину планеты  от северного полюса к южному полюсу.\n",
      "\n",
      "\t\tSentence: Мы знаем, что Земля вращается вокруг своей оси, то есть планет движется вокруг невидимой линии, которая идет через середину планеты  от северного полюса к южному полюсу.\n",
      "\t\tContext: Мы знаем, что Земля вращается вокруг своей оси, то есть планет\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: планет\n",
      "\t\t\t1 predicted token: планетарной\n",
      "\t\tCorrected sentence: Мы знаем, что Земля вращается вокруг своей оси, то есть планетарной движется вокруг невидимой линии, которая идет через середину планеты  от северного полюса к южному полюсу.\n",
      "\t\tSentences:\n",
      "\t\t\tМы знаем, что Земля вращается вокруг своей оси, то есть планета  движется вокруг невидимой линии, которая идет через середину планета от северного полюса к южному полюсу.\n",
      "\n",
      "\t\tSentence: Мы знаем, что Земля вращается вокруг своей оси, то есть планета  движется вокруг невидимой линии, которая идет через середину планета от северного полюса к южному полюсу.\n",
      "\t\tContext: Мы знаем, что Земля вращается вокруг своей оси, то есть планет\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: планет\n",
      "\t\t\t1 predicted token: планетарной\n",
      "\t\tCorrected sentence: Мы знаем, что Земля вращается вокруг своей оси, то есть планетарной  движется вокруг невидимой линии, которая идет через середину планета от северного полюса к южному полюсу.\n",
      "\t\tSentences:\n",
      "\t\t\tКак вы относитесь к идее исключительно вегетарианского ресторана?&gt;.\n",
      "\t\t\tИсключительно вегетарианский ресторан это очень хорошая идея\n",
      "\t\tSentences:\n",
      "\t\t\tКак Америка, так и Европа мировые лидеры которые имеют международные влияние.\n",
      "\t\tSentences:\n",
      "\t\t\tПочему Сталин одобрял монументальную архитектуру?&gt;.\n",
      "\t\t\tЯ думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображала рост и поднятие страны ее развитие).\n",
      "\n",
      "\t\tSentence: Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображала рост и поднятие страны ее развитие).\n",
      "\t\tContext: Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отобража\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 25, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: отобража\n",
      "\t\t\t1 predicted token: отображает\n",
      "\t\tCorrected sentence: Я думаю, что Сталин одобрял такой стиль архитектуры, потому что это отображает рост и поднятие страны ее развитие).\n",
      "\t\tSentences:\n",
      "\t\t\tListen to the video and answer the questions&gt;. аккредитация это подтверждение кредитов, который которые студента учась в университете.\n",
      "\n",
      "\t\tSentence: Listen to the video and answer the questions&gt;. аккредитация это подтверждение кредитов, который которые студента учась в университете.\n",
      "\t\tContext: Listen to the video and answer the questions&gt;. аккредитация это подтверждение кредитов, который которые студент\n",
      "\t\tKeyword stem: студент\n",
      "\t\t\t1 predicted token: студент\n",
      "\t\tCorrected sentence: Listen to the video and answer the questions&gt;. аккредитация это подтверждение кредитов, который которые студент учась в университете.\n",
      "\t\tSentences:\n",
      "\t\t\tTranslate the questions and answer them&gt;.\n",
      "\t\t\tЧто было самой главной проблем Петра Первого, когда он принимал престол?\n",
      "\n",
      "\t\tSentence: Что было самой главной проблем Петра Первого, когда он принимал престол?\n",
      "\t\tContext: Что было самой главной пробл\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: пробл\n",
      "\t\t\t1 predicted token: проблмой\n",
      "\t\tCorrected sentence: Что было самой главной проблмой Петра Первого, когда он принимал престол?\n",
      "\t\tSentences:\n",
      "\t\t\tTranslate the questions and answer them&gt;.\n",
      "\t\t\tЧто было самой главный проблемой Петра Первого, когда он принимал престол?\n",
      "\n",
      "\t\tSentence: Что было самой главный проблемой Петра Первого, когда он принимал престол?\n",
      "\t\tContext: Что было самой главн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: главн\n",
      "\t\t\t1 predicted token: главнй\n",
      "\t\tCorrected sentence: Что было самой главнй проблемой Петра Первого, когда он принимал престол?\n",
      "\t\tSentences:\n",
      "\t\t\tTranslate the questions and answer them&gt;.\n",
      "\t\t\tЧто было самый главной проблемой Петра Первого, когда он принимал престол?\n",
      "\n",
      "\t\tSentence: Что было самый главной проблемой Петра Первого, когда он принимал престол?\n",
      "\t\tContext: Что было сам\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: сам\n",
      "\t\t\t1 predicted token: сам\n",
      "\t\tCorrected sentence: Что было сам главной проблемой Петра Первого, когда он принимал престол?\n",
      "\t\tSentences:\n",
      "\t\t\tПродается квартира на Кудринской площади, находящееся в одной из семи сталинских высоток.\n",
      "\n",
      "\t\tSentence: Продается квартира на Кудринской площади, находящееся в одной из семи сталинских высоток.\n",
      "\t\tContext: Продается квартира на Кудринской площади, находя\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tKeyword stem: находя\n",
      "\t\t\t1 predicted token: находящеся\n",
      "\t\tCorrected sentence: Продается квартира на Кудринской площади, находящеся в одной из семи сталинских высоток.\n",
      "\t\tSentences:\n",
      "\t\t\tКак вы понимаете фразу: «Мы рабы слов»?&gt;.\n",
      "\t\t\tЗа: необходимость осознать точку зрения, котором формируется на основе источников, доверность системы.\n",
      "\n",
      "\t\tSentence: За: необходимость осознать точку зрения, котором формируется на основе источников, доверность системы.\n",
      "\t\tContext: За: необходимость осознать точку зрения, котор\n",
      "\t\tKeyword stem: котор\n",
      "\t\t\t1 predicted token: котор...\n",
      "\t\tCorrected sentence: За: необходимость осознать точку зрения, котор... формируется на основе источников, доверность системы.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-32cbb704ffd8>:23: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "process_file(file_list[7])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO27NmXsmmR3c7mH097T3PF",
   "gpuType": "T4",
   "mount_file_id": "1Q0-ZFJQoaD9j6tUm7napAinsrk-Y8Gzi",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07c310134c4d4a8f9b5a4ce59666cc2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_685f8dea66cc4c54ac3e8ec18d350cad",
       "IPY_MODEL_3ad4b242950c46dfac06bafe10008fbd",
       "IPY_MODEL_71e5996754ea4927867f35a1f93cfff9"
      ],
      "layout": "IPY_MODEL_d4b6a3e330db456ba7143a6e23735117"
     }
    },
    "080867ff6a804bf9a7fdfbdd092a6415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ba7ad0594ee452aaa9e04c835b3310e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dd0a972e0e842da8366940050f6a1d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acb9cbf4ee624a21ab5516860465b3aa",
      "placeholder": "​",
      "style": "IPY_MODEL_5466d2e4fde2472a9c7b47604e8d36a9",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "0e95fbe4ef424e4aae15afff92572b35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e6eedaabaf426f81cc3c5247b72bd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "120405f3fe2342338c881c6e21ae7632": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ab28141ee9c436897c4865280a5d929": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ef693077cae49dd936058e6e6ed689a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "205e55ef30dc4c0ca3fee6cd361b13f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c99b533e545459eb648e769835f2cfa",
      "max": 643916,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5863ff15bb3e4be490916a299b4671b5",
      "value": 643916
     }
    },
    "2073ce8df65a49d3b27666bdfea49112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24224a94199a407a84b956960c02b4a8",
      "placeholder": "​",
      "style": "IPY_MODEL_e032a7f770c04572a4edc01d09135c03",
      "value": " 3.14G/3.14G [01:06&lt;00:00, 184MB/s]"
     }
    },
    "24224a94199a407a84b956960c02b4a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24384ecfcfff4c4aa3f4c847748ba99f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ad4b242950c46dfac06bafe10008fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_486e80eeafdb4d4aa551fbfd4b5682d8",
      "max": 609,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b934aef406a4158a708c70b58b539f1",
      "value": 609
     }
    },
    "40f3f653f81c4d9f96ec541fab12085f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "441d3947af8e413abca456612cf39934": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "486e80eeafdb4d4aa551fbfd4b5682d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b6e98de6af84781aa41afc60a84af84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cfc03e6f94e4982b70fc2e0cb81c051",
      "placeholder": "​",
      "style": "IPY_MODEL_770efc9cd1c04d0499ca443975f0780a",
      "value": " 644k/644k [00:00&lt;00:00, 8.98MB/s]"
     }
    },
    "4ec3b4a310994450ba5983fc4d8655ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50e4444211654baf9908e7f8935222f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_686bd4c5e88d4e958c9b78b96ee8a656",
       "IPY_MODEL_cf7735c37a534e96bc8c66881294fb5b",
       "IPY_MODEL_2073ce8df65a49d3b27666bdfea49112"
      ],
      "layout": "IPY_MODEL_120405f3fe2342338c881c6e21ae7632"
     }
    },
    "53b1349a4fb24fe4a6435c07ebe90999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0944970655f4c90a76e39620b3ab386",
      "max": 30022,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe5fde3a4e66414d846723f87497aa62",
      "value": 30022
     }
    },
    "5466d2e4fde2472a9c7b47604e8d36a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5863ff15bb3e4be490916a299b4671b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a10c9072aa545d188732af8c514af11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a57d269824944159361e707ce8ca2ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cfc03e6f94e4982b70fc2e0cb81c051": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63544048820347ae9c3b6a7f387e40b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "641e8f5b06fb4c7b88a02a85a900a473": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67af8e974ca94888a3090e0ddc83f677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "685f8dea66cc4c54ac3e8ec18d350cad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10e6eedaabaf426f81cc3c5247b72bd2",
      "placeholder": "​",
      "style": "IPY_MODEL_b663098b9c3248ab82108918588d975b",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "686bd4c5e88d4e958c9b78b96ee8a656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ba7ad0594ee452aaa9e04c835b3310e",
      "placeholder": "​",
      "style": "IPY_MODEL_6a015793117a435a9c01c2283b7e9ec6",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "6a015793117a435a9c01c2283b7e9ec6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a44a1b377094f0fbca63bdff2f14129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b52d8532d5674ee593772b407dc447f1",
      "max": 1713123,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_441d3947af8e413abca456612cf39934",
      "value": 1713123
     }
    },
    "6c0f23ae0d404f67bda820dc7543b636": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24384ecfcfff4c4aa3f4c847748ba99f",
      "placeholder": "​",
      "style": "IPY_MODEL_1ef693077cae49dd936058e6e6ed689a",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "71e5996754ea4927867f35a1f93cfff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c185f092bdbf4d76b838441cd7272116",
      "placeholder": "​",
      "style": "IPY_MODEL_1ab28141ee9c436897c4865280a5d929",
      "value": " 609/609 [00:00&lt;00:00, 27.0kB/s]"
     }
    },
    "751ff156e04142c0a25abefb1e3e91e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af7301d5720e4b5ca1908f47bece509c",
      "placeholder": "​",
      "style": "IPY_MODEL_d6bdd28df792498a9ec39e1fcfb73c76",
      "value": " 1.71M/1.71M [00:00&lt;00:00, 14.8MB/s]"
     }
    },
    "770efc9cd1c04d0499ca443975f0780a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8580e7f0f04b405e97f36b3480443cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca3e30d1daa349bba2ad9b4b0351e53b",
       "IPY_MODEL_53b1349a4fb24fe4a6435c07ebe90999",
       "IPY_MODEL_e22b9f0a665740579009b2593b1dbb3e"
      ],
      "layout": "IPY_MODEL_90dc24b74bb540e988b19972f13f49bb"
     }
    },
    "8648e773e1b44174b07071b8ac3f7fe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ec3b4a310994450ba5983fc4d8655ea",
      "max": 1270925,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d238e01415cc4b72a71411bc5de98476",
      "value": 1270925
     }
    },
    "8b3c8f756e8c46c49adcae662c7c0634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c0f23ae0d404f67bda820dc7543b636",
       "IPY_MODEL_8648e773e1b44174b07071b8ac3f7fe6",
       "IPY_MODEL_e331ec720edd4077a43f03866e373dfd"
      ],
      "layout": "IPY_MODEL_5a10c9072aa545d188732af8c514af11"
     }
    },
    "907e1afdb5a044d8814ad3d0d2a9e1b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "90dc24b74bb540e988b19972f13f49bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b934aef406a4158a708c70b58b539f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9c99b533e545459eb648e769835f2cfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb9cbf4ee624a21ab5516860465b3aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9158bf2fb646008af4912e30a3690e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da11079ff3724c3b9764f801b29d78e9",
       "IPY_MODEL_205e55ef30dc4c0ca3fee6cd361b13f4",
       "IPY_MODEL_4b6e98de6af84781aa41afc60a84af84"
      ],
      "layout": "IPY_MODEL_40f3f653f81c4d9f96ec541fab12085f"
     }
    },
    "af7301d5720e4b5ca1908f47bece509c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b327a53aa73a4665b8da3658e8d894f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b52d8532d5674ee593772b407dc447f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b663098b9c3248ab82108918588d975b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7115c590f8c4a40a9744efb84ab55ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c185f092bdbf4d76b838441cd7272116": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7d37fedb0174cfc98e3cddb49dca8c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dd0a972e0e842da8366940050f6a1d7",
       "IPY_MODEL_6a44a1b377094f0fbca63bdff2f14129",
       "IPY_MODEL_751ff156e04142c0a25abefb1e3e91e3"
      ],
      "layout": "IPY_MODEL_641e8f5b06fb4c7b88a02a85a900a473"
     }
    },
    "ca3e30d1daa349bba2ad9b4b0351e53b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed449ef6bc8f45149d74b2cd2f530b22",
      "placeholder": "​",
      "style": "IPY_MODEL_b327a53aa73a4665b8da3658e8d894f4",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
     }
    },
    "cb269958e8bf4cfe83b58b252faf83b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf7735c37a534e96bc8c66881294fb5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7115c590f8c4a40a9744efb84ab55ff",
      "max": 3141928084,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_907e1afdb5a044d8814ad3d0d2a9e1b8",
      "value": 3141928084
     }
    },
    "d238e01415cc4b72a71411bc5de98476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4b6a3e330db456ba7143a6e23735117": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6bdd28df792498a9ec39e1fcfb73c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da11079ff3724c3b9764f801b29d78e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a57d269824944159361e707ce8ca2ef",
      "placeholder": "​",
      "style": "IPY_MODEL_080867ff6a804bf9a7fdfbdd092a6415",
      "value": "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.5.0/models/tokenize/gsd.pt: 100%"
     }
    },
    "e032a7f770c04572a4edc01d09135c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0944970655f4c90a76e39620b3ab386": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e22b9f0a665740579009b2593b1dbb3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb269958e8bf4cfe83b58b252faf83b7",
      "placeholder": "​",
      "style": "IPY_MODEL_67af8e974ca94888a3090e0ddc83f677",
      "value": " 216k/? [00:00&lt;00:00, 12.5MB/s]"
     }
    },
    "e331ec720edd4077a43f03866e373dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e95fbe4ef424e4aae15afff92572b35",
      "placeholder": "​",
      "style": "IPY_MODEL_63544048820347ae9c3b6a7f387e40b3",
      "value": " 1.27M/1.27M [00:00&lt;00:00, 47.9MB/s]"
     }
    },
    "ed449ef6bc8f45149d74b2cd2f530b22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe5fde3a4e66414d846723f87497aa62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
